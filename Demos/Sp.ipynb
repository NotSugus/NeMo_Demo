{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown --id 1jZ4HvYcAXI5ZClke2iGA7qFQQJBXIovw -O tts_model.pth.tar \n",
    "!gdown --id 1s7g4n-B73ChCB48AQ88_DV_8oyLth8r0 -O config.json\n",
    "!gdown --id 13st0CZ743v6Br5R5Qw_lH1OPQOr3M-Jv -O scale_stats.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown --id 14MlX3EY5KuXA5GVglyd2i1EXu8ApHNsS -O vocoder_model.pth.tar\n",
    "!gdown --id 1uBRVNxsoCYJxNCqPoQedASm6EtSW3w04 -O config_vocoder.json\n",
    "!gdown --id 1O8ziB27XqzIpkb-6_QI0fpDouF4-v7_1 -O scale_stats_vocoder.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install espeak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/coqui-ai/TTS TTS_repo\n",
    "%cd TTS_repo\n",
    "!git checkout 4873601\n",
    "!pip install -r requirements.txt\n",
    "!python setup.py develop\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_vocoder_input(scale_factor, spec):\n",
    "    \"\"\"Interpolation to tolarate the sampling rate difference\n",
    "    btw tts model and vocoder\"\"\"\n",
    "    print(\" > before interpolation :\", spec.shape)\n",
    "    spec = torch.tensor(spec).unsqueeze(0).unsqueeze(0)\n",
    "    spec = torch.nn.functional.interpolate(spec, scale_factor=scale_factor, mode='bilinear').squeeze(0)\n",
    "    print(\" > after interpolation :\", spec.shape)\n",
    "    return spec\n",
    "\n",
    "\n",
    "def tts(model, text, CONFIG, use_cuda, ap, use_gl, figures=True):\n",
    "    t_1 = time.time()\n",
    "    waveform, alignment, mel_spec, mel_postnet_spec, stop_tokens, inputs = synthesis(model, text, CONFIG, use_cuda, ap, speaker_id, style_wav=None,\n",
    "                                                                             truncated=False, enable_eos_bos_chars=CONFIG.enable_eos_bos_chars)\n",
    "    print(mel_postnet_spec.shape)\n",
    "    mel_postnet_spec = ap._denormalize(mel_postnet_spec.T).T\n",
    "    if not use_gl:\n",
    "        target_sr = VOCODER_CONFIG.audio['sample_rate']\n",
    "        vocoder_input = ap_vocoder._normalize(mel_postnet_spec.T)\n",
    "        if scale_factor[1] != 1:\n",
    "            vocoder_input = interpolate_vocoder_input(scale_factor, vocoder_input)\n",
    "        else:\n",
    "            vocoder_input = torch.tensor(vocoder_input).unsqueeze(0)\n",
    "        waveform = vocoder_model.inference(vocoder_input)\n",
    "    if use_cuda and not use_gl:\n",
    "        waveform = waveform.cpu()\n",
    "    if not use_gl:\n",
    "        waveform = waveform.numpy()\n",
    "    waveform = waveform.squeeze()\n",
    "    rtf = (time.time() - t_1) / (len(waveform) / ap.sample_rate)\n",
    "    tps = (time.time() - t_1) / len(waveform)\n",
    "    print(waveform.shape)\n",
    "    print(\" > Run-time: {}\".format(time.time() - t_1))\n",
    "    print(\" > Real-time factor: {}\".format(rtf))\n",
    "    print(\" > Time per step: {}\".format(tps))\n",
    "    IPython.display.display(IPython.display.Audio(waveform, rate=VOCODER_CONFIG.audio['sample_rate']))  \n",
    "    return alignment, mel_postnet_spec, stop_tokens, waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "import IPython\n",
    "\n",
    "# for some reason TTS installation does not work on Colab\n",
    "sys.path.append('TTS_repo')\n",
    "\n",
    "from TTS.tts.utils.generic_utils import setup_model\n",
    "from TTS.utils.io import load_config\n",
    "from TTS.tts.utils.text.symbols import symbols, phonemes\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "from TTS.tts.utils.synthesis import synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime settings\n",
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model paths\n",
    "TTS_MODEL = \"tts_model.pth.tar\"\n",
    "TTS_CONFIG = \"config.json\"\n",
    "VOCODER_MODEL = \"vocoder_model.pth.tar\"\n",
    "VOCODER_CONFIG = \"config_vocoder.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load configs\n",
    "TTS_CONFIG = load_config(TTS_CONFIG)\n",
    "VOCODER_CONFIG = load_config(VOCODER_CONFIG)\n",
    "VOCODER_CONFIG.audio['stats_path'] = 'scale_stats_vocoder.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the audio processor\n",
    "ap = AudioProcessor(**TTS_CONFIG.audio)    \n",
    "ap_vocoder = AudioProcessor(**VOCODER_CONFIG['audio'])   \n",
    "\n",
    "# scale factor for sampling rate difference\n",
    "scale_factor = [1,  VOCODER_CONFIG['audio']['sample_rate'] / ap.sample_rate]\n",
    "print(f\"scale_factor: {scale_factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TTS MODEL\n",
    "# multi speaker \n",
    "speaker_id = None\n",
    "speakers = []\n",
    "\n",
    "# load the model\n",
    "num_chars = len(phonemes) if TTS_CONFIG.use_phonemes else len(symbols)\n",
    "model = setup_model(num_chars, len(speakers), TTS_CONFIG)\n",
    "\n",
    "# load model state\n",
    "cp =  torch.load(TTS_MODEL, map_location=torch.device('cpu'))\n",
    "\n",
    "# load the model\n",
    "model.load_state_dict(cp['model'])\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "model.eval()\n",
    "\n",
    "# set model stepsize\n",
    "if 'r' in cp:\n",
    "    model.decoder.set_r(cp['r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.vocoder.utils.generic_utils import setup_generator\n",
    "\n",
    "# LOAD VOCODER MODEL\n",
    "vocoder_model = setup_generator(VOCODER_CONFIG)\n",
    "vocoder_model.load_state_dict(torch.load(VOCODER_MODEL, map_location=\"cpu\")[\"model\"])\n",
    "vocoder_model.remove_weight_norm()\n",
    "vocoder_model.inference_padding = 0\n",
    " \n",
    "if use_cuda:\n",
    "    vocoder_model.cuda()\n",
    "vocoder_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence =  \"Ay mi madre, vaya golazo del polaco\"\n",
    "align, spec, stop_tokens, wav = tts(model, sentence, TTS_CONFIG, use_cuda, ap, use_gl=False, figures=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
